# -*- coding: utf-8 -*-
"""localization-set3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XvKyhOfmBE-3SACyjV4YGoXltc33Z34Y
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import datetime
import os
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model
import pathlib
from google.colab import files
from pandas import *

#from zipfile import ZipFile

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
from zipfile import ZipFile
file_name = "/content/drive/MyDrive/ds03-rs150-v0.zip"

with ZipFile(file_name, 'r') as zipp:
  zipp.extractall()
  print('Done')

#EXTRACT FROM ZIP
#file_name = "/content/ds03-toy-test.zip"
#with ZipFile(file_name, 'r') as zip:
#  zip.extractall()
#  print('Done')

# Model hyperparameters

# True if training is skiped, and the model is loaded
skip_training = False

#Related to input image
img_height = 150
img_width = 150
IMG_SIZE = (img_height, img_width)

#CNN hyperparameters
num_classes = 8
batch_size = 32
train_batch_size = 32
train_frozen_epochs = 15
train_unfrozen_epochs = 15
train_learning_rate =0.001
train_dropout=0.5
train_learning_rate_decrease = 100
unfrozen_layers = 100  #out of 175

#Load the data into train and val set

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  '/content/ds03-rs150-v0/train',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  '/content/ds03-rs150-v0/validation',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names

#TF setup
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

#Base model
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')

#MODEL DEFINITION

#Data augmentation block
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),
  tf.keras.layers.experimental.preprocessing.RandomContrast(
    factor=0.6),
])

#Resnet preprocessing
preprocess_input = tf.keras.applications.resnet.preprocess_input

#Prediction block
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
dropout_layer = tf.keras.layers.Dropout(train_dropout)
prediction_layer = tf.keras.layers.Dense(num_classes, activation='sigmoid')

###############################################
inputs = tf.keras.Input(shape=(img_height, img_width, 3))
x = data_augmentation(inputs)


x = preprocess_input(x) 
x = base_model(x, training=False)
x = global_average_layer(x)
#x= tf.keras.layers.BatchNormalization(axis=1)(x)
x = dropout_layer(x)
outputs = prediction_layer(x)
#################################################
model = tf.keras.Model(inputs, outputs)

base_model.trainable = False

model.summary()

base_learning_rate = train_learning_rate
#Multiple class loss
model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

#TRAINING PART

print('------------MODEL----------- ')
print('')
print('Input image size: '+str(IMG_SIZE))
print('Number of classes: '+str(num_classes))
print('Batch size: '+str(batch_size))
print('Initial learing rate: '+str(train_learning_rate))
print('Learning rate drecerase ratio: '+str(train_learning_rate_decrease))
print('Droput ratio: '+str(train_dropout))
print('Frozen epochs: '+str(train_frozen_epochs))
print('Unfrozen epochs: '+str(train_unfrozen_epochs))
print('Total epochs: '+str(train_frozen_epochs+train_unfrozen_epochs))
print('')
print('--------------------------------')


if skip_training==False:
  epochs=train_frozen_epochs 

  class myCallback(tf.keras.callbacks.Callback):
          def on_epoch_end(self, epoch, logs={}):
            if(logs.get('acc') is not None and logs.get('acc')>0.98):
                print("\nReached 99.8% accuracy so cancelling training!")
                self.model.stop_training = True

  callbacks = myCallback()

  history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs,
  batch_size=train_batch_size,
  callbacks=[callbacks]
    )
  base_model.trainable = True
  

  # Fine-tune from this layer onwards
  print("Number of layers in the base model: ", len(base_model.layers))

  fine_tune_at = unfrozen_layers

  # Freeze all the layers before the `fine_tune_at` layer
  for layer in base_model.layers[:fine_tune_at]:
    layer.trainable =  False

  fine_tune_epochs = train_unfrozen_epochs
  total_epochs =  epochs + fine_tune_epochs


  #Multiple classes
  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/train_learning_rate_decrease),
              metrics=['accuracy'])
  
  history_fine = model.fit(train_ds,
                         epochs=total_epochs,
                         initial_epoch=history.epoch[-1],
                         validation_data=val_ds,
                         batch_size = train_batch_size,
                         callbacks=[callbacks])




  model.save('model-test4')


else:
  pass
    #model = tf.keras.models.load_model('model-test4')

print("Validation")
results = model.evaluate(val_ds)
print("val loss, val acc:", results)

#-----------------------------MODEL VALIDATION PART----------------------

#Plot train and validation loss and accuracy during training

if skip_training==False:
    acc = history.history['accuracy']
    print(len(acc))
    val_acc = history.history['val_accuracy']

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs_range = range(epochs)
    acc += history_fine.history['accuracy']
    val_acc += history_fine.history['val_accuracy']

    loss += history_fine.history['loss']
    val_loss += history_fine.history['val_loss']

print(len(acc))

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.ylim([0, 1.0])
plt.plot([epochs-1,epochs-1],
          plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.ylim([0, 1.0])
plt.plot([epochs-1,epochs-1],
         plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

#CONFUSSION MATRIX OF THE VALDIATION SET

#Retrieve a batch of images from the test set
tt=val_ds.as_numpy_iterator()
image_batch, label_batch = tt.next()



#plt.figure(figsize=(10, 10))
#for i in range(15):
 # ax = plt.subplot(4, 4, i + 1)
  #plt.imshow(image_batch[i].astype("uint8"))
  #plt.title(class_names[predictions[i]] + class_names[label_batch[i]])
  #plt.axis("off")
#plt.show()

TP=0
FP=0
TN=0
FN=0
cont = 0
matrix = [[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]]
#t = 3296 // 2 
t = 3376 // batch_size

images = []
true=[]
predicted=[]
for i in range(t):
  predictions = model.predict_on_batch(image_batch)
  predictions= np.argmax(predictions, axis = 1)
  for j in range(len(predictions)): # 0 1 2 3 4 5 6 
    cont = cont + 1
    p = predictions[j]
    t = label_batch[j]
    if p != t:
      true.append(t)
      predicted.append(p)
      images.append(image_batch[j])
     
    matrix[t][p]+=1
  image_batch, label_batch = tt.next()

predictions = model.predict_on_batch(image_batch)
predictions= np.argmax(predictions, axis = 1)

for j in range(len(predictions)):
    cont = cont + 1
    p = predictions[j]
    t = label_batch[j]
    if p != t:
      images.append(image_batch[j])
      true.append(t)
      predicted.append(p)
    matrix[t][p]+=1


print('TOTAL VALIDATION IMAGES!!:'+str(cont))
print('')
print('')
print('---------------------- CONFUSION MATRIX -----------')
print('')

confusion_matrix = [[" ", class_names[0],class_names[1],class_names[2],class_names[3],class_names[4],class_names[5],class_names[6], class_names[7]],[class_names[0],matrix[0][0],matrix[0][1],matrix[0][2],matrix[0][3],matrix[0][4],matrix[0][5],matrix[0][6],matrix[0][7]],[class_names[1],matrix[1][0],matrix[1][1],matrix[1][2],matrix[1][3],matrix[1][4],matrix[1][5],matrix[1][6],matrix[1][7]],[class_names[2],matrix[2][0],matrix[2][1],matrix[2][2],matrix[2][3],matrix[2][4],matrix[2][5],matrix[2][6],matrix[2][7]],[class_names[3],matrix[3][0],matrix[3][1],matrix[3][2],matrix[3][3],matrix[3][4],matrix[3][5],matrix[3][6],matrix[3][7]],[class_names[4],matrix[4][0],matrix[4][1],matrix[4][2],matrix[4][3],matrix[4][4],matrix[4][5],matrix[4][6],matrix[4][7]],[class_names[5],matrix[5][0],matrix[5][1],matrix[5][2],matrix[5][3],matrix[5][4],matrix[5][5],matrix[5][6],matrix[5][7]],[class_names[6],matrix[6][0],matrix[6][1],matrix[6][2],matrix[6][3],matrix[6][4],matrix[6][5],matrix[6][6],matrix[6][7]],[class_names[7],matrix[7][0],matrix[7][1],matrix[7][2],matrix[7][3],matrix[7][4],matrix[7][5],matrix[7][6],matrix[7][7]]]
D = DataFrame(confusion_matrix)
print(D.to_string(index=False))

print('')
print('Percentages:')
p0 = (matrix[0][0])/(matrix[0][0] + matrix[0][1] + matrix[0][2] + matrix[0][3] + matrix[0][4] + matrix[0][5] + matrix[0][6] + matrix[0][7]) * 100
p1 = (matrix[1][1])/(matrix[1][0] + matrix[1][1] + matrix[1][2] + matrix[1][3] + matrix[1][4] + matrix[1][5] + matrix[1][6] + matrix[1][7]) * 100
p2 = (matrix[2][2])/(matrix[2][0] + matrix[2][1] + matrix[2][2] + matrix[2][3] + matrix[2][4] + matrix[2][5] + matrix[2][6] + matrix[2][7]) * 100
p3 = (matrix[3][3])/(matrix[3][0] + matrix[3][1] + matrix[3][2] + matrix[3][3] + matrix[3][4] + matrix[3][5] + matrix[3][6] + matrix[3][7]) * 100
p4 = (matrix[4][4])/(matrix[4][0] + matrix[4][1] + matrix[4][2] + matrix[4][3] + matrix[4][4] + matrix[4][5] + matrix[4][6] + matrix[4][7]) * 100
p5 = (matrix[5][5])/(matrix[5][0] + matrix[5][1] + matrix[5][2] + matrix[5][3] + matrix[5][4] + matrix[5][5] + matrix[5][6] + matrix[5][7]) * 100
p6 = (matrix[6][6])/(matrix[6][0] + matrix[6][1] + matrix[6][2] + matrix[6][3] + matrix[6][4] + matrix[6][5] + matrix[6][6] + matrix[6][7]) * 100
p7 = (matrix[7][7])/(matrix[7][0] + matrix[7][1] + matrix[7][2] + matrix[7][3] + matrix[7][4] + matrix[7][5] + matrix[7][6] + matrix[7][7]) * 100
print(class_names[0]+ ': ' + str(p0))
print(class_names[1]+ ': ' + str(p1))
print(class_names[2]+ ': ' + str(p2))
print(class_names[3]+ ': ' + str(p3))
print(class_names[4]+ ': ' + str(p4))
print(class_names[5]+ ': ' + str(p5))
print(class_names[6]+ ': ' + str(p6))
print(class_names[7]+ ': ' + str(p7))
print('')
print('')
print('')
print('----------------- FAILED PREDICTIONS --------------')
print('Fails:' + str(len(predicted)))

plt.figure(figsize=(20, 80))
for i in range(43):
  ax = plt.subplot(23, 2, i + 1)
  plt.imshow(images[i].astype("uint8"))
  plt.title('T:' + class_names[true[i]]+"/" + 'P:' + class_names[predicted[i]])
  plt.axis("off")
plt.show()

#MODEL VISUALIZATION 

#To get a feel for what kind of features our convnet has learned, one fun thing to do is to visualize how an input gets transformed as it goes through the convnet.

#Let's pick a random cat or dog image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map. Rerun this cell to generate intermediate representations for a variety of training images.

import numpy as np
from keras import models 
import random
from   tensorflow.keras.preprocessing.image import img_to_array, load_img

# Let's define a new Model that will take an image as input, and will output
# intermediate representations for all layers in the previous model after
# the first.
successive_outputs = [layer.output for layer in base_model.layers[1:]]
print(successive_outputs)

#visualization_model = Model(img_input, successive_outputs)
visualization_model = tf.keras.models.Model(inputs = base_model.input, outputs = successive_outputs)


train_aerofreno_dir = '/content/ds03-rs150-v0/train/AEROFRENO'
train_punta_dir = '/content/ds03-rs150-v0/train/PUNTA'

train_aerofreno_fnames = os.listdir( train_aerofreno_dir )
train_punta_fnames = os.listdir( train_punta_dir )

aerofreno_img_files = [os.path.join(train_aerofreno_dir, f) for f in train_aerofreno_fnames]
punta_img_files = [os.path.join(train_punta_dir, f) for f in train_punta_fnames]

img_path = random.choice(aerofreno_img_files + punta_img_files)
img = load_img(img_path, target_size=(150, 150)) # this is a PIL image

x   = img_to_array(img)                           # Numpy array with shape (224, 224, 3)
x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 224, 224, 3)

pre = tf.keras.applications.resnet.preprocess_input
x = pre(x)


# Let's run our image through our network, thus obtaining all
# intermediate representations for this image.
successive_feature_maps = visualization_model.predict(x)



activations = successive_feature_maps
first_layer_activation = activations[0]


# These are the names of the layers, so can have them as part of our plot
layer_names = [layer.name for layer in base_model.layers]


#plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')

# -----------------------------------------------------------------------
# Now let's display our representations
# -----------------------------------------------------------------------

print('HI')
print(len(successive_feature_maps))

print(successive_feature_maps[5].shape)

print(len(layer_names))

#successive_feature_maps = successive_feature_maps[:5]

for layer_name, feature_map in zip(layer_names, successive_feature_maps):
  
  if len(feature_map.shape) == 4:
    
    #-------------------------------------------
    # Just do this for the conv / maxpool layers, not the fully-connected layers
    #-------------------------------------------
    n_features = feature_map.shape[-1]  # number of features in the feature map

    feature_threshold = 6
    if n_features > feature_threshold:
      n_features = feature_threshold
    
    size = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)
    
    # We will tile our images in this matrix
    display_grid = np.zeros((size, size * n_features))
    
    #-------------------------------------------------
    # Postprocess the feature to be visually palatable
    #-------------------------------------------------
    for i in range(n_features):
      x  = feature_map[0, :, :, i]
      x -= x.mean()
      x /= x.std ()
      x *=  64
      x += 128
      x  = np.clip(x, 0, 255).astype('uint8')
      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid

    #-----------------
    # Display the grid
    #-----------------

    scale = 20. / n_features
    plt.figure( figsize=(scale * n_features, scale) )
    plt.title ( layer_name )
    plt.grid  ( False )
    plt.imshow( display_grid, aspect='auto', cmap='viridis' )

class_names = ['AERODINAMICO', 'AEROFRENO', 'BORDE', 'COMPLETO', 'PIEZA', 'PUNTA', 'VALVAS', 'ZOOM']
path = '/content/ds03-rs150-v0/validation/VALVAS'
images = os.listdir(path)
cont = 0

for i in range(len(images)):
  image_path = path+'/'+images[i]
  img = keras.preprocessing.image.load_img(
    image_path, target_size=(img_height, img_width)
  )

  img_array = keras.preprocessing.image.img_to_array(img)
  img_array = tf.expand_dims(img_array, 0) # Create a batch
  predictions = model.predict_on_batch(img_array).flatten()


  predicted_class = class_names[np.argmax(predictions)]

  if predicted_class != 'VALVAS':
    cont += 1
    print('-----------------')
    print('')
    print(images[i])
    print(predicted_class)
  

print(cont)